\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
     \usepackage[nonatbib]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{YOLO-Vacant Parking Spot Detector}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Andrew Park \\
  Electrical and Computer Engineering\\
  A17406465\\
  % examples of more authors
  \And
  Minsang Kim \\
  Electrical and Computer Engineering\\
  A16636382 \\
}

\begin{document}

\maketitle

\begin{abstract}
    Describe the overall picture of your project here. Give a short description about the different parts you are going to cover in the proposal, but do not include too many details here.
    
    We do not have requirements for the code. The only requirement is that it should be from you, not copy paste from online repo.
    

\end{abstract}

\section{Introduction}

Finding a vacant parking space in a given lot is a tedious and costly task: a person must drive through the whole parking lot in order to find a vacant space. This uneffective process will 
waste gasoline and time while searching for a parking space. Furtermore, this will cause congestion in the parking lot. Therefore, by displaying the occupancy of spaces in a given parking lot
will significantly reduce the time cost, traffic congestion, and gasoline consumption. YOLO-Parking will aid this wasteful process by displaying vacant and
occupied parking spaces. Although there are existing methods to detect the occupancy of a parking space, such as car detector on every parking space and other object detector architectures 
that detects the occupancy, most of them are expensive or slow in detecting parking spots\cite{DBLP:journals/corr/abs-2107-12207}. Furthermore, there are several traditional models  models 
to detect the instance segmentation of a vacant parking spot, but they are slow in detection for videos. 

In this paper, we propose a new model to detect vacant parking spots: You Only Look Once (YOLO). YOLO architecture is one of the fastest architecture that accurately performs object detection \cite{redmon2016look}. 
Additionally, several cameras mounted in the parking lot to detect vacancy of a space is relatively cheaper than placing a car detector on every parking space in a parking lot \cite{DBLP:journals/corr/abs-2107-12207}. 



\section{Related Work}

\textbf{R-CNN} \quad R-CNN \cite{DBLP:journals/corr/abs-2107-12207} is a widely used object detecting CNN model with relatively high accuracy. The first step is to regional proposal using selective search methods to propose bounding box. 
Then, for each region proposal, the model warped the propsed regions to use them as inputs for a convolutional neural network. The CNN classifies eacn input proposed region using SVM specific to a class \cite{girshick2014rich}. 
However, the training rate is slow due to large number of parameters to learn, and the inference rate is also slow. In one of the previous approaches in detecting parking spots, Martin Marek proposed R-CNN: the model first pool 
proposed parking spot patches in the original image and then a CNN produces a binary output whether the space in each patch is occupied or not \cite{DBLP:journals/corr/abs-2107-12207}. The authors provided two methods for pooling
for the first step in R-CNN: the interpolation of pixels to construct quadrilateral bounding boxes and construction of minimal bounding boxes \cite{DBLP:journals/corr/abs-2107-12207}. 

\textbf{Faster R-CNN FPN} The input image first undergoes a feature pyramid network (FPN). Then, the authors extract the features of the parking spots and pass them through respective classification head for classification. However, 
the input image must be resized, thus limiting the output image from being full resolution \cite{DBLP:journals/corr/abs-2107-12207}. Both R-CNN and R-CNN is still slow in inference for object detection in videos. Faster R-CNN can use
one of the two methods of pooling mentioned above \cite{DBLP:journals/corr/abs-2107-12207}. 

These two models are merely the baseline of parking vacancy object detector using CNN. In this paper, we intend to improve the model in inference time by using YOLO model. 

\section{Method}

In this section, you should describe your method (Do not need to be the exact method you describe in project proposal). Besides, You can include the following things(You do not have to cover all of them): 

\begin{itemize}
    \item the detailed structure of your method, including the formulations, network architecture figure.
    \item training algorithm, testing algorithm.
    \item what is the new proposed techniques compared to previous work, and the reason and strength of choosing the method.
\end{itemize}

\section{Experiments}

In this section, You should include the following things:

\begin{itemize}
    \item the datasets you use:
        \subitem the brief introduction of the dataset
        \subitem the data format
        \subitem other information related to your experiments
    \item your results
    \item ablation study on training your networks, how does the method work with more or less data, with/without some components (optional)
\end{itemize}


\section{Supplementary Material}

You should also include a video recording a presentation (with motivation, approach, results) for this project.

\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}
